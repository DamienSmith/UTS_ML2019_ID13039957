{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DamienSmith/UTS_ML2019_ID13039957/blob/master/A2_PracticalProject_13039957_13026998.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWf4FTWL7mhY",
        "colab_type": "text"
      },
      "source": [
        "# A2: Practical Machine Learning Project | 31005 | Advanced Data Analytics\n",
        "Student: 13039957 & 13026998\n",
        "\n",
        "Link to Github:\n",
        "https://github.com/DamienSmith/UTS_ML2019_ID13039957/blob/master/A2_PracticalProject_13039957_13026998.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0-ciK386-52",
        "colab_type": "text"
      },
      "source": [
        "##Introduction (100)\n",
        "\n",
        "Project overview.\n",
        "\n",
        "**Discuss the Algorithm** \n",
        "* Linear regression or decision tree\n",
        "\n",
        "**Define Input/Output** \n",
        "* What data you use and what youâ€™re getting out\n",
        "* the format of the I/O data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-076P8Yx6-iu",
        "colab_type": "text"
      },
      "source": [
        "##Exploration (300)\n",
        "\n",
        "**Identify Challenges**\n",
        "\n",
        "* Highlight the practical significance of the project\n",
        "* What problems exist and how to manage them\n",
        "  * e.g. memory management, time efficiency, 'advanced functions' (eg parallelism) \n",
        "\n",
        "**Design Data Structures**\n",
        "\n",
        "* Design/planning of research/development is clear and logical\n",
        "* Cover these:\n",
        "  * data acquisition\n",
        "  * quality control\n",
        "  * modelling technicques\n",
        "  * evaluation method & criteria\n",
        "\n",
        "**Plan Data Models and Tests**\n",
        "\n",
        "* Logical design (correct, efficient and practically complete)\n",
        "* Evaluation method/Testing (Compare and consider alternatives)\n",
        "* Must be able to run code through collab \n",
        "  * i.e. data load and python libraries need to work in Collab\n",
        "\n",
        "\n",
        "**Possible alternatives**\n",
        "\n",
        "* Algorithm Tuning. The application of CART to the Bank Note dataset was not tuned. Experiment with different parameter values and see if you can achieve better performance.\n",
        "\n",
        "* Cross Entropy. Another cost function for evaluating splits is cross entropy (logloss). You could implement and experiment with this alternative cost function.\n",
        "\n",
        "* Tree Pruning. An important technique for reducing overfitting of the training dataset is to prune the trees. Investigate and implement tree pruning methods.\n",
        "\n",
        "* Categorical Dataset. The example was designed for input data with numerical or ordinal input attributes, experiment with categorical input data and splits that may use equality instead of ranking.\n",
        "\n",
        "* Regression. Adapt the tree for regression using a different cost function and method for creating terminal nodes.\n",
        "\n",
        "* More Datasets. Apply the algorithm to more datasets on the UCI Machine Learning Repository.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv3kz8Cx6-bm",
        "colab_type": "text"
      },
      "source": [
        "##Methodology (100 ex comments)\n",
        "\n",
        "[code here]\n",
        "\n",
        "**Build and Train Data Models**\n",
        "\n",
        "* Comments connect the code to the algorithm steps\n",
        "* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9F55nV5LWxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## \n",
        "##    A2: Practical Machine Learning Project | 31005 | Advanced Data Analytics\n",
        "##    \n",
        "##    Authors: Rae Ho (13026998) & Damien Smith (13039957)\n",
        "##    Goals: - Implement Decision Tree Algorithm\n",
        "##           - Build & Train a model\n",
        "##           - Explore/Compare alternative options within the algorithm\n",
        "##    Code: Python 3\n",
        "##    Github: https://github.com/DamienSmith/UTS_ML2019_ID13039957/blob/master/A2_PracticalProject_13039957_13026998.ipynb\n",
        "##\n",
        "##\n",
        "\n",
        "# Import Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load Data\n",
        "# Just some test data\n",
        "dataset = [[2.771244718,1.784783929,0],\n",
        "\t[1.728571309,1.169761413,0],\n",
        "\t[3.678319846,2.81281357,0],\n",
        "\t[3.961043357,2.61995032,0],\n",
        "\t[2.999208922,2.209014212,0],\n",
        "\t[7.497545867,3.162953546,1],\n",
        "\t[9.00220326,3.339047188,1],\n",
        "\t[7.444542326,0.476683375,1],\n",
        "\t[10.12493903,3.234550982,1],\n",
        "\t[6.642287351,3.319983761,1]]\n",
        "\n",
        "dataset\n",
        "\n",
        "plt.show(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv4S9QNXQsBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Gini_index() Function \n",
        "# Calculate the Gini index for a split dataset\n",
        "\n",
        "def gini_index(groups, classes):\n",
        "\t# count all samples at split point\n",
        "\tn_instances = float(sum([len(group) for group in groups]))\n",
        "\t# sum weighted Gini index for each group\n",
        "\tgini = 0.0\n",
        "\tfor group in groups:\n",
        "\t\tsize = float(len(group))\n",
        "\t\t# avoid divide by zero\n",
        "\t\tif size == 0:\n",
        "\t\t\tcontinue\n",
        "\t\tscore = 0.0\n",
        "\t\t# score the group based on the score for each class\n",
        "\t\tfor class_val in classes:\n",
        "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
        "\t\t\tscore += p * p\n",
        "\t\t# weight the group score by its relative size\n",
        "\t\tgini += (1.0 - score) * (size / n_instances)\n",
        "\treturn gini\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShJDI7lFQuDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d14ebbb6-689f-4c5c-8950-3a1c9583b930"
      },
      "source": [
        "# Define worst_gini_index_test() Function\n",
        "# Test on worst-case where there is a 50/50 split on each group\n",
        "# For a comparison\n",
        "\n",
        "def worst_gini_index_test(groups, classes):\n",
        "\t# count all samples at split point\n",
        "\tn_instances = float(sum([len(group) for group in groups]))\n",
        "\t# sum weighted Gini index for each group\n",
        "\tgini = 0.0\n",
        "\tfor group in groups:\n",
        "\t\tsize = float(len(group))\n",
        "\t\t# avoid divide by zero\n",
        "\t\tif size == 0:\n",
        "\t\t\tcontinue\n",
        "\t\tscore = 0.0\n",
        "\t\t# score the group based on the score for each class\n",
        "\t\tfor class_val in classes:\n",
        "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
        "\t\t\tscore += p * p\n",
        "\t\t# weight the group score by its relative size\n",
        "\t\tgini += (1.0 - score) * (size / n_instances)\n",
        "\treturn gini\n",
        " \n",
        "# test Gini values\n",
        "print(gini_index([[[1, 1], [1, 0]], [[1, 1], [1, 0]]], [0, 1]))\n",
        "print(gini_index([[[1, 0], [1, 0]], [[1, 1], [1, 1]]], [0, 1]))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JyFVr7NRfop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define test_split() Function.\n",
        "# Separate the dataset into two lists of rows given the index of an attribute and a split value for that attribute.\n",
        "# Once we have the two groups, we can then use our Gini score above to evaluate the cost of the split.\n",
        "# Note: The right group contains all rows with a value at the index above or equal to the split value.\n",
        "\n",
        "# Split a dataset based on an attribute and an attribute value\n",
        "def test_split(index, value, dataset):\n",
        "\tleft, right = list(), list()\n",
        "\tfor row in dataset:\n",
        "\t\tif row[index] < value:\n",
        "\t\t\tleft.append(row)\n",
        "\t\telse:\n",
        "\t\t\tright.append(row)\n",
        "\treturn left, right\n",
        "\n",
        "\n",
        "# Splitting a dataset involves iterating over each row, checking if the attribute value is below or above the split value and assigning it to the left or right group respectively."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy5EjwWHSKzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define get_split() Function.\n",
        "# With the Gini function above and the test split function we now have everything we need to evaluate splits.\n",
        "# Given a dataset, we must check every value on each attribute as a candidate split, evaluate the cost of the split and find the best possible split we could make.\n",
        "# Once the best split is found, we can use it as a node in our decision tree\n",
        "\n",
        "def get_split(dataset):\n",
        "\tclass_values = list(set(row[-1] for row in dataset))\n",
        "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "\tfor index in range(len(dataset[0])-1):\n",
        "\t\tfor row in dataset:\n",
        "\t\t\tgroups = test_split(index, row[index], dataset)\n",
        "\t\t\tgini = gini_index(groups, class_values)\n",
        "\t\t\tprint('X%d < %.3f Gini=%.3f' % ((index+1), row[index], gini))\n",
        "\t\t\tif gini < b_score:\n",
        "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO8C9l0hXOSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a43046ef-a334-489c-dd60-50861b39ceed"
      },
      "source": [
        "# Calculate the Gini index for a split dataset\n",
        "def gini_index(groups, classes):\n",
        "\t# count all samples at split point\n",
        "\tn_instances = float(sum([len(group) for group in groups]))\n",
        "\t# sum weighted Gini index for each group\n",
        "\tgini = 0.0\n",
        "\tfor group in groups:\n",
        "\t\tsize = float(len(group))\n",
        "\t\t# avoid divide by zero\n",
        "\t\tif size == 0:\n",
        "\t\t\tcontinue\n",
        "\t\tscore = 0.0\n",
        "\t\t# score the group based on the score for each class\n",
        "\t\tfor class_val in classes:\n",
        "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
        "\t\t\tscore += p * p\n",
        "\t\t# weight the group score by its relative size\n",
        "\t\tgini += (1.0 - score) * (size / n_instances)\n",
        "\treturn gini\n",
        "\n",
        "# Split a dataset based on an attribute and an attribute value\n",
        "def test_split(index, value, dataset):\n",
        "\tleft, right = list(), list()\n",
        "\tfor row in dataset:\n",
        "\t\tif row[index] < value:\n",
        "\t\t\tleft.append(row)\n",
        "\t\telse:\n",
        "\t\t\tright.append(row)\n",
        "\treturn left, right\n",
        "\n",
        "# Select the best split point for a dataset\n",
        "def get_split(dataset):\n",
        "\tclass_values = list(set(row[-1] for row in dataset))\n",
        "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "\tfor index in range(len(dataset[0])-1):\n",
        "\t\tfor row in dataset:\n",
        "\t\t\tgroups = test_split(index, row[index], dataset)\n",
        "\t\t\tgini = gini_index(groups, class_values)\n",
        "\t\t\tprint('X%d < %.3f Gini=%.3f' % ((index+1), row[index], gini))\n",
        "\t\t\tif gini < b_score:\n",
        "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
        " \n",
        "split = get_split(dataset)\n",
        "print('Split: [X%d < %.3f]' % ((split['index']+1), split['value']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X1 < 2.771 Gini=0.444\n",
            "X1 < 1.729 Gini=0.500\n",
            "X1 < 3.678 Gini=0.286\n",
            "X1 < 3.961 Gini=0.167\n",
            "X1 < 2.999 Gini=0.375\n",
            "X1 < 7.498 Gini=0.286\n",
            "X1 < 9.002 Gini=0.375\n",
            "X1 < 7.445 Gini=0.167\n",
            "X1 < 10.125 Gini=0.444\n",
            "X1 < 6.642 Gini=0.000\n",
            "X2 < 1.785 Gini=0.500\n",
            "X2 < 1.170 Gini=0.444\n",
            "X2 < 2.813 Gini=0.320\n",
            "X2 < 2.620 Gini=0.417\n",
            "X2 < 2.209 Gini=0.476\n",
            "X2 < 3.163 Gini=0.167\n",
            "X2 < 3.339 Gini=0.444\n",
            "X2 < 0.477 Gini=0.500\n",
            "X2 < 3.235 Gini=0.286\n",
            "X2 < 3.320 Gini=0.375\n",
            "Split: [X1 < 6.642]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YGS3CuVZD4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "08d26ad4-0246-484e-f613-f8b3a5bf5e55"
      },
      "source": [
        "# plot scatter plot - needs work\n",
        "\n",
        "# ax.scatter(groups, list(set(row[-1] for row in dataset)), marker=verts)\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-98f462628eb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'groups' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8Vaj5HThPEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to control the size of a tree by defining the depth and the number of rows that a node will run.\n",
        "\n",
        "# We use user-defined arguments to define tree building procedure.\n",
        "# Maximum Tree Depth. This is the maximum number of nodes from the root node of the tree. Once a maximum depth of the tree is met, we must stop splitting adding new nodes. Deeper trees are more complex and are more likely to overfit the training data.\n",
        "# Minimum Node Records. This is the minimum number of training patterns that a given node is responsible for. Once at or below this minimum, we must stop splitting and adding new nodes. Nodes that account for too few training patterns are expected to be too specific and are likely to overfit the training data.\n",
        "\n",
        "# There is one more condition. It is possible to choose a split in which all rows belong to one group. In this case, we will be unable to continue splitting and adding child nodes as we will have no records to split on one side or another.\n",
        "\n",
        "# Now we have some ideas of when to stop growing the tree. When we do stop growing at a given point, that node is called a terminal node and is used to make a final prediction.\n",
        "\n",
        "# This is done by taking the group of rows assigned to that node and selecting the most common class value in the group. This will be used to make predictions.\n",
        "\n",
        "\n",
        "# Define to_terminal() Function\n",
        "# Select a class value for a group of rows. It returns the most common output value in a list of rows.\n",
        "def to_terminal(group):\n",
        "\toutcomes = [row[-1] for row in group]\n",
        "\treturn max(set(outcomes), key=outcomes.count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FkenWeghnVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Split a dataset based on an attribute and an attribute value\n",
        "def test_split(index, value, dataset):\n",
        "\tleft, right = list(), list()\n",
        "\tfor row in dataset:\n",
        "\t\tif row[index] < value:\n",
        "\t\t\tleft.append(row)\n",
        "\t\telse:\n",
        "\t\t\tright.append(row)\n",
        "\treturn left, right\n",
        " \n",
        "# Calculate the Gini index for a split dataset\n",
        "def gini_index(groups, classes):\n",
        "\t# count all samples at split point\n",
        "\tn_instances = float(sum([len(group) for group in groups]))\n",
        "\t# sum weighted Gini index for each group\n",
        "\tgini = 0.0\n",
        "\tfor group in groups:\n",
        "\t\tsize = float(len(group))\n",
        "\t\t# avoid divide by zero\n",
        "\t\tif size == 0:\n",
        "\t\t\tcontinue\n",
        "\t\tscore = 0.0\n",
        "\t\t# score the group based on the score for each class\n",
        "\t\tfor class_val in classes:\n",
        "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
        "\t\t\tscore += p * p\n",
        "\t\t# weight the group score by its relative size\n",
        "\t\tgini += (1.0 - score) * (size / n_instances)\n",
        "\treturn gini\n",
        " \n",
        "# Select the best split point for a dataset\n",
        "def get_split(dataset):\n",
        "\tclass_values = list(set(row[-1] for row in dataset))\n",
        "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "\tfor index in range(len(dataset[0])-1):\n",
        "\t\tfor row in dataset:\n",
        "\t\t\tgroups = test_split(index, row[index], dataset)\n",
        "\t\t\tgini = gini_index(groups, class_values)\n",
        "\t\t\tif gini < b_score:\n",
        "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
        " \n",
        "# Create a terminal node value\n",
        "def to_terminal(group):\n",
        "\toutcomes = [row[-1] for row in group]\n",
        "\treturn max(set(outcomes), key=outcomes.count)\n",
        " \n",
        "# Create child splits for a node or make terminal\n",
        "def split(node, max_depth, min_size, depth):\n",
        "\tleft, right = node['groups']\n",
        "\tdel(node['groups'])\n",
        "\t# check for a no split\n",
        "\tif not left or not right:\n",
        "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
        "\t\treturn\n",
        "\t# check for max depth\n",
        "\tif depth >= max_depth:\n",
        "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
        "\t\treturn\n",
        "\t# process left child\n",
        "\tif len(left) <= min_size:\n",
        "\t\tnode['left'] = to_terminal(left)\n",
        "\telse:\n",
        "\t\tnode['left'] = get_split(left)\n",
        "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
        "\t# process right child\n",
        "\tif len(right) <= min_size:\n",
        "\t\tnode['right'] = to_terminal(right)\n",
        "\telse:\n",
        "\t\tnode['right'] = get_split(right)\n",
        "\t\tsplit(node['right'], max_depth, min_size, depth+1)\n",
        "    \n",
        "# Build a decision tree\n",
        "def build_tree(train, max_depth, min_size):\n",
        "\troot = get_split(train)\n",
        "\tsplit(root, max_depth, min_size, 1)\n",
        "\treturn root\n",
        " \n",
        "# Print a decision tree\n",
        "def print_tree(node, depth=0):\n",
        "\tif isinstance(node, dict):\n",
        "\t\tprint('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
        "\t\tprint_tree(node['left'], depth+1)\n",
        "\t\tprint_tree(node['right'], depth+1)\n",
        "\telse:\n",
        "\t\tprint('%s[%s]' % ((depth*' ', node)))\n",
        "\n",
        "tree = build_tree(dataset, 1, 1)\n",
        "print_tree(tree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4yODkiVhnO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## show some experimenting with different 'max depth' parameters\n",
        "\n",
        "##\n",
        "\n",
        "##\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dg4c-2LiL2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a prediction with a decision tree\n",
        "def predict(node, row):\n",
        "\tif row[node['index']] < node['value']:\n",
        "\t\tif isinstance(node['left'], dict):\n",
        "\t\t\treturn predict(node['left'], row)\n",
        "\t\telse:\n",
        "\t\t\treturn node['left']\n",
        "\telse:\n",
        "\t\tif isinstance(node['right'], dict):\n",
        "\t\t\treturn predict(node['right'], row)\n",
        "\t\telse:\n",
        "\t\t\treturn node['right']\n",
        "    \n",
        "#  predict with a stump\n",
        "stump = {'index': 0, 'right': 1, 'value': 6.642287351, 'left': 0}\n",
        "for row in dataset:\n",
        "\tprediction = predict(stump, row)\n",
        "\tprint('Predicted=%d, Result=%d' % (row[-1], prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk89B4XCiy6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Comparisons\n",
        "\n",
        "## Regression?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISzhqah26-KQ",
        "colab_type": "text"
      },
      "source": [
        "##Evaluation (200)\n",
        "\n",
        "\n",
        "**Report Execution on Data**\n",
        "\n",
        "**Report Testing**\n",
        "\n",
        "**Efficiency Analysis**\n",
        "\n",
        "**Comparative Study**\n",
        "\n",
        "ideas:\n",
        "* how does each feature distribution look like? Are there any differences between feature distribution in train and test data?\n",
        "* are there any meaningful interactions between the features?\n",
        "* are there outliers and can they be explained?\n",
        "* are there missing values or duplicates? What are reasons for them?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-FTRF_s85K_",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion (100)\n",
        "\n",
        "\n",
        "Discuss Reflections\n",
        "\n",
        "Propose Possible Improvements\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLV7jwde8-oX",
        "colab_type": "text"
      },
      "source": [
        "## Ethical (200)\n",
        "\n",
        "* Discuss the social/ethical aspect of the project\n",
        "  * adopt an ethical model (e.g. Ultitarian or Kantian)\n",
        "* Consider how the technique could be misused"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdspPnHH9Cn3",
        "colab_type": "text"
      },
      "source": [
        "## Video Pitch\n",
        "\n",
        "[url to video]\n",
        "\n",
        "**Highlight Challenges and Effort**\n",
        "\n",
        "* Describe challenges and how the team addressed them."
      ]
    }
  ]
}